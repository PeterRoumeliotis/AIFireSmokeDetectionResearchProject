{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJjtFvQ14dMwEJCIbO1+v4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterRoumeliotis/AIFireSmokeDetectionResearchProject/blob/main/AIFireAndSmokeDetectionResearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import kagglehub\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "zvi-1Xsl4HBM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading latest version of the dataset I am using\n",
        "path = kagglehub.dataset_download(\"phylake1337/fire-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa7tmbqc0Q8L",
        "outputId": "d7d4badd-7b3c-4d3b-c993-89519a7e9a90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/fire-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "# Getting the source paths\n",
        "source_dir = '/kaggle/input/fire-dataset/fire_dataset'\n",
        "source_fire_dir = os.path.join(source_dir, 'fire_images')\n",
        "source_non_fire_dir = os.path.join(source_dir, 'non_fire_images')\n",
        "\n",
        "# Creating training and validation paths\n",
        "dest_dir = 'data'\n",
        "train_fire_dir = os.path.join(dest_dir, 'train', 'fire')\n",
        "val_fire_dir = os.path.join(dest_dir, 'validation', 'fire')\n",
        "train_non_fire_dir = os.path.join(dest_dir, 'train', 'non_fire')\n",
        "val_non_fire_dir = os.path.join(dest_dir, 'validation', 'non_fire')\n",
        "\n",
        "# Making sure the directories exist and if they dont, making them\n",
        "os.makedirs(train_fire_dir, exist_ok=True)\n",
        "os.makedirs(val_fire_dir, exist_ok=True)\n",
        "os.makedirs(train_non_fire_dir, exist_ok=True)\n",
        "os.makedirs(val_non_fire_dir, exist_ok=True)\n",
        "\n",
        "# 80% training 20% validation\n",
        "split_ratio = 0.8\n",
        "\n",
        "# Splitting the files into each folder\n",
        "def split_data(source_folder, train_folder, val_folder, split_ratio=0.8):\n",
        "\n",
        "    # List all items in source folder and keep only files\n",
        "    file_list = [f for f in os.listdir(source_folder) if os.path.isfile(os.path.join(source_folder, f))]\n",
        "    # Randomizes it\n",
        "    random.shuffle(file_list)\n",
        "\n",
        "    # Figures out at what index to split the files\n",
        "    split_point = int(len(file_list) * split_ratio)\n",
        "    train_files = file_list[:split_point]   # Training\n",
        "    val_files = file_list[split_point:]   # Validation\n",
        "\n",
        "    # Copying files into training\n",
        "    for file_name in train_files:\n",
        "        src = os.path.join(source_folder, file_name)\n",
        "        dst = os.path.join(train_folder, file_name)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    # Copying files into validation\n",
        "    for file_name in val_files:\n",
        "        src = os.path.join(source_folder, file_name)\n",
        "        dst = os.path.join(val_folder, file_name)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "split_data(source_fire_dir, train_fire_dir, val_fire_dir, split_ratio)\n",
        "split_data(source_non_fire_dir, train_non_fire_dir, val_non_fire_dir, split_ratio)\n",
        "\n",
        "print(\"Data is split\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-dze51z4LiM",
        "outputId": "fed43a9a-6e39-40e5-9c53-8cff2c9ae391"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data is split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150, 150\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/validation'\n",
        "\n",
        "# Augmenting training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescaling validation data\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Generate validation batches\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjOVd_4N4Xtx",
        "outputId": "9a5fac7f-1bb9-4f7c-e516-b2fe87adc721"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 799 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Model"
      ],
      "metadata": {
        "id": "CpBTYw6NzERN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "QMGJigXYwhac",
        "outputId": "d2a0f0af-c2ca-4296-838c-8b2b42c3b753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,785\u001b[0m (432.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,785</span> (432.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,337\u001b[0m (431.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,337</span> (431.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=train_generator.samples, epochs=epochs, validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "model_save_path = \"fire_detection_cnn.keras\"\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-TpDsn4fqE",
        "outputId": "4066666f-43ce-4fce-fa16-0e6a32c7be42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m 25/799\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:22\u001b[0m 805ms/step - accuracy: 0.8421 - loss: 0.3683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 31ms/step - accuracy: 0.8799 - loss: 0.2694 - val_accuracy: 0.7656 - val_loss: 0.5798\n",
            "Epoch 2/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9339 - loss: 0.1519 - val_accuracy: 0.7500 - val_loss: 0.5337\n",
            "Epoch 3/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9278 - loss: 0.1481 - val_accuracy: 0.7552 - val_loss: 0.4518\n",
            "Epoch 4/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9310 - loss: 0.1758 - val_accuracy: 0.7500 - val_loss: 0.4527\n",
            "Epoch 5/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9440 - loss: 0.1460 - val_accuracy: 0.7552 - val_loss: 0.5055\n",
            "Epoch 6/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9421 - loss: 0.1373 - val_accuracy: 0.7500 - val_loss: 0.6712\n",
            "Epoch 7/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9396 - loss: 0.1317 - val_accuracy: 0.7604 - val_loss: 0.4310\n",
            "Epoch 8/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9501 - loss: 0.1346 - val_accuracy: 0.7656 - val_loss: 0.4687\n",
            "Epoch 9/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9485 - loss: 0.1298 - val_accuracy: 0.8229 - val_loss: 0.3546\n",
            "Epoch 10/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9484 - loss: 0.1198 - val_accuracy: 0.8438 - val_loss: 0.3765\n",
            "Epoch 11/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9499 - loss: 0.1114 - val_accuracy: 0.7969 - val_loss: 0.4615\n",
            "Epoch 12/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9561 - loss: 0.1037 - val_accuracy: 0.8333 - val_loss: 0.4438\n",
            "Epoch 13/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9576 - loss: 0.1163 - val_accuracy: 0.8594 - val_loss: 0.3579\n",
            "Epoch 14/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9460 - loss: 0.1176 - val_accuracy: 0.7917 - val_loss: 0.4269\n",
            "Epoch 15/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9648 - loss: 0.0991 - val_accuracy: 0.6875 - val_loss: 0.6054\n",
            "Epoch 16/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9588 - loss: 0.1000 - val_accuracy: 0.7865 - val_loss: 0.4875\n",
            "Epoch 17/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - accuracy: 0.9474 - loss: 0.1118 - val_accuracy: 0.6510 - val_loss: 0.6587\n",
            "Epoch 18/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9682 - loss: 0.0949 - val_accuracy: 0.8750 - val_loss: 0.2976\n",
            "Epoch 19/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9715 - loss: 0.0816 - val_accuracy: 0.8177 - val_loss: 0.3944\n",
            "Epoch 20/20\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9661 - loss: 0.0715 - val_accuracy: 0.9375 - val_loss: 0.2103\n",
            "Model saved to fire_detection_cnn.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --quiet"
      ],
      "metadata": {
        "id": "kPIEF1DJv4bw",
        "outputId": "7993a43f-7140-48a6-c290-b4f67341b95e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/\n",
        "# https://www.digitalocean.com/community/tutorials/train-yolov5-custom-data\n",
        "# Sources I used to help me format my dataset for yolo\n",
        "\n",
        "for split in [\"train\",\"validation\"]:\n",
        "    for cls_idx, cls in enumerate([\"non_fire\",\"fire\"]):\n",
        "        folder = f\"data/{split}/{cls}\"\n",
        "        for img in os.listdir(folder):\n",
        "            # Skips non images\n",
        "            if not img.lower().endswith((\".jpg\",\".png\")): continue\n",
        "            img_path   = os.path.join(folder, img)\n",
        "            label_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "\n",
        "            if cls == \"fire\":\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    # Formats data for yolo\n",
        "                    f.write(f\"{1} 0.5 0.5 1.0 1.0\\n\")\n",
        "            else:\n",
        "                open(label_path, \"w\").close()\n"
      ],
      "metadata": {
        "id": "8A9iHkLYAb31"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making YAML for yolo\n",
        "\n",
        "# https://docs.ultralytics.com/\n",
        "# https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/\n",
        "\n",
        "# Used these sources for help\n",
        "\n",
        "%%bash\n",
        "cat <<EOF > data/fire_data.yaml\n",
        "train: /content/data/train\n",
        "val:   /content/data/validation\n",
        "\n",
        "names:\n",
        "  0: non_fire\n",
        "  1: fire\n",
        "EOF\n",
        "\n",
        "echo \"Created YAML:\"\n",
        "cat data/fire_data.yaml\n"
      ],
      "metadata": {
        "id": "c3_4wD-twKV4",
        "outputId": "72bd0b69-f8ef-42a5-adff-74a40bf9958f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created YAML:\n",
            "train: /content/data/train\n",
            "val:   /content/data/validation\n",
            "\n",
            "names:\n",
            "  0: non_fire\n",
            "  1: fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "yolo = YOLO('yolov8n.pt')\n",
        "\n",
        "yolo.train(\n",
        "    data='data/fire_data.yaml',\n",
        "    epochs=20,\n",
        "    imgsz=150,\n",
        "    batch=32,\n",
        "    project='yolo-fire',\n",
        "    name='exp'\n",
        ")\n",
        "\n",
        "yolo_model = YOLO('yolo-fire/exp/weights/best.pt')\n"
      ],
      "metadata": {
        "id": "9f2AG7tcwNnD",
        "outputId": "ac4b5a9b-c6ae-4c33-df96-8d835222ee86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.119 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data/fire_data.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=150, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolo-fire, name=exp, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=yolo-fire/exp\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 20.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 83.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[150] must be multiple of max stride 32, updating to [160]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1571.5±1476.0 MB/s, size: 66.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/fire... 798 images, 194 backgrounds, 1 corrupt: 100%|██████████| 799/799 [00:00<00:00, 994.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/fire/fire.357.png: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/fire/fire.576.png: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/fire/fire.681.png: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/non_fire/non_fire.189.png: ignoring corrupt image/label: invalid image format GIF. Supported formats are:\n",
            "images: {'dng', 'bmp', 'jpeg', 'pfm', 'tif', 'heic', 'png', 'jpg', 'webp', 'mpo', 'tiff'}\n",
            "videos: {'mpeg', 'mp4', 'avi', 'wmv', 'm4v', 'mov', 'webm', 'mpg', 'mkv', 'ts', 'gif', 'asf'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/fire.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 620.2±160.6 MB/s, size: 299.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/validation/fire... 200 images, 49 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<00:00, 1785.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation/fire.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to yolo-fire/exp/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 160 train, 160 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolo-fire/exp\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20     0.346G     0.7383      2.439      1.165         70        160: 100%|██████████| 25/25 [00:13<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.874      0.919      0.963      0.916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20     0.363G      0.415     0.7979     0.9826         74        160: 100%|██████████| 25/25 [00:11<00:00,  2.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.635      0.914      0.763      0.574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20     0.391G      0.369     0.6833     0.9576         70        160: 100%|██████████| 25/25 [00:12<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.953      0.937      0.983      0.954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20     0.408G     0.3392     0.5962     0.9437         76        160: 100%|██████████| 25/25 [00:12<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.978      0.894       0.98      0.923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20     0.424G     0.3307     0.5787     0.9406         76        160: 100%|██████████| 25/25 [00:12<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.898      0.818      0.912      0.859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20     0.441G     0.3022     0.5082     0.9244         79        160: 100%|██████████| 25/25 [00:12<00:00,  2.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.982      0.921      0.982      0.964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20     0.459G     0.2992     0.4709     0.9234         75        160: 100%|██████████| 25/25 [00:11<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.969      0.817      0.927      0.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20     0.477G     0.2694     0.4694       0.92         72        160: 100%|██████████| 25/25 [00:12<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.905      0.885      0.949      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20     0.492G     0.2557     0.4373     0.9088         69        160: 100%|██████████| 25/25 [00:12<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.914       0.96      0.972      0.951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      0.51G     0.2366     0.4088     0.9052         74        160: 100%|██████████| 25/25 [00:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.912      0.934      0.958      0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20     0.525G     0.2273     0.6916     0.8797         28        160: 100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.864      0.927      0.874      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20     0.543G     0.1914     0.3964     0.8642         20        160: 100%|██████████| 25/25 [00:11<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.987      0.993      0.991       0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20     0.561G     0.1663     0.3085     0.8471         23        160: 100%|██████████| 25/25 [00:11<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.973          1      0.994      0.993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20     0.578G     0.1517     0.2911     0.8601         24        160: 100%|██████████| 25/25 [00:12<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.982      0.993      0.993       0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20     0.594G       0.13     0.2557     0.8466         22        160: 100%|██████████| 25/25 [00:10<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.987      0.994      0.994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20     0.611G     0.1221     0.2316     0.8498         22        160: 100%|██████████| 25/25 [00:11<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.993      0.995      0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20     0.629G     0.1173     0.2191     0.8409         24        160: 100%|██████████| 25/25 [00:12<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.992      0.987      0.995      0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20     0.645G     0.1013      0.193     0.8465         25        160: 100%|██████████| 25/25 [00:12<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.993      0.995      0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20     0.662G    0.09611     0.1787     0.8522         21        160: 100%|██████████| 25/25 [00:12<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.993      0.995      0.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      0.68G    0.09009     0.1858     0.8338         27        160: 100%|██████████| 25/25 [00:10<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.993      0.994      0.994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.085 hours.\n",
            "Optimizer stripped from yolo-fire/exp/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from yolo-fire/exp/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating yolo-fire/exp/weights/best.pt...\n",
            "Ultralytics 8.3.119 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        151      0.993      0.993      0.995      0.995\n",
            "                  fire        151        151      0.993      0.993      0.995      0.995\n",
            "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1myolo-fire/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.load_model('fire_detection_cnn.keras')\n",
        "yolo_model = YOLO('yolo-fire/exp/weights/best.pt')\n",
        "\n",
        "# Upload/open vid\n",
        "uploaded = files.upload()\n",
        "video_path = next(iter(uploaded.keys()))\n",
        "print(f\"Video file: {video_path}\")\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Frames per second, default is 30\n",
        "fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "\n",
        "frame_indices = []  # Frame numbers\n",
        "cnn_flags     = []  # My model\n",
        "yolo_flags    = []  # Yolo\n",
        "\n",
        "frame_idx = 0\n",
        "\n",
        "# Loop through vid by frame\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_idx += 1\n",
        "\n",
        "    # My model detection\n",
        "    # Resize/normalize\n",
        "    img = cv2.resize(frame, (150,150)) / 255.0\n",
        "    # Get the fire probability from my model\n",
        "    p = cnn_model.predict(np.expand_dims(img,0), verbose=0)[0][0]\n",
        "    # Detect if probability > 0.5\n",
        "    cnn_detected = (p > 0.5)\n",
        "\n",
        "    # YOLO detection\n",
        "    # Run yolo\n",
        "    res = yolo_model(frame, verbose=False)[0]\n",
        "    classes = res.boxes.cls.cpu().numpy().astype(int).tolist()\n",
        "    # Detect if there is class 1 (fire)\n",
        "    yolo_detected = (1 in classes)\n",
        "\n",
        "    # Results\n",
        "    frame_indices.append(frame_idx)\n",
        "    cnn_flags.append(cnn_detected)\n",
        "    yolo_flags.append(yolo_detected)\n",
        "\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "z2-L6mgayG04",
        "outputId": "cf974652-a6fa-4bfb-892c-256571d2e073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-038c5992-f366-47a5-af5b-8b0890908f04\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-038c5992-f366-47a5-af5b-8b0890908f04\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Yosemite Forest Fire Time Lapse and Flyover.mp4 to Yosemite Forest Fire Time Lapse and Flyover (1).mp4\n",
            "Video file: Yosemite Forest Fire Time Lapse and Flyover (1).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cnn_frames = [frame_indices[i] for i, flag in enumerate(cnn_flags) if flag]\n",
        "yolo_frames = [frame_indices[i] for i, flag in enumerate(yolo_flags) if flag]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
        "\n",
        "# My model detections (red circles)\n",
        "ax1.scatter(cnn_frames, [1]*len(cnn_frames),\n",
        "            label='My model detected', marker='o', c='red')\n",
        "ax1.set_yticks([1])\n",
        "ax1.set_yticklabels(['My model fire'])\n",
        "ax1.set_title('My model per‐frame detections')\n",
        "\n",
        "# Yolo detections (blue X’s)\n",
        "ax2.scatter(yolo_frames, [1]*len(yolo_frames),\n",
        "            label='Yolo detected', marker='x', c='blue')\n",
        "ax2.set_yticks([1])\n",
        "ax2.set_yticklabels(['Yolo fire'])\n",
        "ax2.set_title('Yolo per‐frame detections')\n",
        "\n",
        "ax2.set_xlabel('Frame Number')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UMgiH6PfjkaU",
        "outputId": "c60bf4df-38e0-41f6-8aa0-b623b81b9b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}